{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, LinearSVR\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3320000000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>348000000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0   0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "1   1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00  11927742.92   \n",
       "2   2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "3   3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   6324375.16   \n",
       "4   4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "\n",
       "        x008       x009  ...    x757           x758  x759   x760  x761   x762  \\\n",
       "0   934577.0    14539.0  ...  0.0007      297281012  0.13    5.0     5    2.0   \n",
       "1  1798051.0  1051272.0  ...  0.1136  3320000000000  0.08  661.0     0  350.0   \n",
       "2   375738.0   144143.0  ...  0.0029      100474819  0.39   39.0     2   18.0   \n",
       "3  1932094.0    10055.0  ...  0.0000   348000000000  0.25    2.0     1    0.0   \n",
       "4   474253.0    17914.0  ...  0.0005      109546590  0.11   11.0     1    3.0   \n",
       "\n",
       "      x763    x764  x765   y  \n",
       "0   8.5127   14.28 -0.75   5  \n",
       "1   1.5700  160.12   NaN   1  \n",
       "2   9.6800   25.06 -0.49  11  \n",
       "3   4.5316  117.76  1.64   1  \n",
       "4  16.2717    5.81 -0.42   5  \n",
       "\n",
       "[5 rows x 756 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()\n",
    "df = df.select_dtypes('number')\n",
    "df.head()\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.isnan(X_train).any(axis=1)\n",
    "#X_train = X_train[~mask]\n",
    "\n",
    "mask = np.isnan(X_val).any(axis=1)\n",
    "X_val = X_val[~mask]\n",
    "y_val = y_val[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>26900000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>135000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>6000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.377769e+10</td>\n",
       "      <td>27776.26</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00505</td>\n",
       "      <td>5.472212e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10797026.17</td>\n",
       "      <td>4501083.0</td>\n",
       "      <td>7538720.0</td>\n",
       "      <td>229000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>154000000000000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>4.5550</td>\n",
       "      <td>271.84</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.583740e+10</td>\n",
       "      <td>17060.72</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>2.262486e+09</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10151935.50</td>\n",
       "      <td>2262318.0</td>\n",
       "      <td>4887848.0</td>\n",
       "      <td>131000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3041</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>7170000000000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>5.5842</td>\n",
       "      <td>137.96</td>\n",
       "      <td>-0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 765 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "5  4.377769e+10  27776.26  6.02  0.00505  5.472212e+09  0.50  10797026.17   \n",
       "7  1.583740e+10  17060.72  5.73  0.00275  2.262486e+09  0.49  10151935.50   \n",
       "\n",
       "        x008       x009                x010  ...    x756    x757  \\\n",
       "0   934577.0    14539.0      26900000000000  ...  1.5707  0.0007   \n",
       "2   375738.0   144143.0     135000000000000  ...  0.4582  0.0029   \n",
       "4   474253.0    17914.0       6000000000000  ...  0.0100  0.0005   \n",
       "5  4501083.0  7538720.0  229000000000000000  ...  0.0000  0.6223   \n",
       "7  2262318.0  4887848.0  131000000000000000  ...  1.3041  0.4630   \n",
       "\n",
       "              x758  x759    x760  x761    x762     x763    x764  x765  \n",
       "0        297281012  0.13     5.0     5     2.0   8.5127   14.28 -0.75  \n",
       "2        100474819  0.39    39.0     2    18.0   9.6800   25.06 -0.49  \n",
       "4        109546590  0.11    11.0     1     3.0  16.2717    5.81 -0.42  \n",
       "5  154000000000000  0.52  1883.0     1  1055.0   4.5550  271.84  0.62  \n",
       "7    7170000000000  0.86  2007.0     1  1113.0   5.5842  137.96 -0.94  \n",
       "\n",
       "[5 rows x 765 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/3556458860.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = df.drop(['id', 'y'], 1)\n"
     ]
    }
   ],
   "source": [
    "# splitting and scaling data\n",
    "X = df.drop(['id', 'y'], 1)\n",
    "y = df['y']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size= .2, random_state=2)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2857"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n",
      "/var/folders/nm/dj6mm3d17ms01cl74p40pj3w0000gn/T/ipykernel_33667/2629514182.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop([col], 1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have dropped the following columns ['x018', 'x035', 'x038', 'x048', 'x049', 'x051', 'x059', 'x061', 'x064', 'x075', 'x077', 'x080', 'x083', 'x090', 'x103', 'x119', 'x135', 'x141', 'x147', 'x165', 'x185', 'x209', 'x241', 'x247', 'x251', 'x252', 'x273', 'x291', 'x294', 'x303', 'x312', 'x314', 'x316', 'x317', 'x334', 'x336', 'x347', 'x357', 'x360', 'x399', 'x408', 'x414', 'x436', 'x447', 'x449', 'x456', 'x467', 'x513', 'x538', 'x559', 'x577', 'x589', 'x595', 'x597', 'x599', 'x604', 'x614', 'x617', 'x620', 'x633', 'x641', 'x647', 'x648', 'x657', 'x658', 'x672', 'x677', 'x680', 'x683', 'x691', 'x693', 'x701', 'x706', 'x712', 'x716', 'x718', 'x732', 'x738', 'x748', 'x765']\n",
      "We dropped 311 rows from the dataframe\n"
     ]
    }
   ],
   "source": [
    "# finding columns with na and removing them\n",
    "\n",
    "def remove_na_cols(df, threshold = .01):\n",
    "    dropped_cols = []\n",
    "    for col in df.columns:\n",
    "        num_nas = sum(df[col].isna())\n",
    "        if num_nas/len(df) > threshold:\n",
    "            df.drop([col], 1, inplace=True)\n",
    "            dropped_cols.append(col)\n",
    "    print(\"We have dropped the following columns\", dropped_cols)\n",
    "    len_pre_drop = len(df)\n",
    "    df = df.dropna()\n",
    "    print(f\"We dropped {len_pre_drop - len(df)} rows from the dataframe\")\n",
    "\n",
    "remove_na_cols(X_train)\n",
    "cols = X_train.columns\n",
    "X_val = X_val[X_train.columns]\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willcichowski/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_selection', SelectFromModel(estimator=LinearSVR())),\n",
       "                ('regression', RandomForestRegressor())])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVR())),\n",
    "  ('regression', RandomForestRegressor())\n",
    "])\n",
    "clf_fit = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99604176e-03, 2.34147793e-03, 6.90095096e-04, 4.81936120e-03,\n",
       "       1.78469537e-03, 2.35817151e-03, 1.43148655e-03, 3.12165850e-03,\n",
       "       5.35854582e-03, 1.10048798e-03, 7.97168607e-03, 1.82760441e-03,\n",
       "       2.35303190e-03, 2.39024423e-03, 7.87656507e-04, 1.06402627e-02,\n",
       "       1.55908637e-04, 4.90376320e-03, 3.14357424e-03, 9.79070265e-04,\n",
       "       1.05216391e-03, 2.25837053e-03, 7.53177823e-04, 1.40010602e-03,\n",
       "       7.88697372e-03, 1.70793223e-02, 2.67376085e-03, 2.33663832e-03,\n",
       "       3.75640595e-04, 1.92648463e-03, 1.15085616e-03, 1.63090382e-03,\n",
       "       4.78023869e-03, 8.58389069e-04, 8.64572044e-04, 1.89299075e-03,\n",
       "       1.49784783e-03, 5.45335890e-02, 5.61974252e-04, 7.17641181e-03,\n",
       "       1.53888591e-03, 6.24530834e-03, 2.10344820e-02, 8.03209355e-03,\n",
       "       2.11466991e-02, 1.71618042e-03, 9.26573089e-04, 3.15555039e-03,\n",
       "       1.62521397e-03, 2.00139787e-03, 2.81628301e-03, 6.95649023e-04,\n",
       "       8.23685869e-02, 7.09200899e-04, 4.28106216e-04, 1.26083516e-03,\n",
       "       9.70779403e-04, 4.48431561e-04, 1.94707065e-03, 4.49991174e-04,\n",
       "       3.07583646e-03, 3.04434630e-03, 3.08459728e-03, 2.08067829e-03,\n",
       "       3.47188005e-03, 4.01202271e-03, 1.30394015e-03, 3.23202740e-03,\n",
       "       3.83293045e-03, 3.32815973e-03, 4.28370274e-03, 4.57417029e-04,\n",
       "       1.26286431e-03, 4.47910636e-03, 4.17126001e-03, 3.63908637e-03,\n",
       "       2.56913106e-03, 3.42703551e-03, 1.42354797e-03, 1.29101306e-03,\n",
       "       4.93414812e-04, 1.84106477e-03, 1.40015126e-03, 8.41088281e-04,\n",
       "       7.66172073e-03, 2.94371860e-03, 4.55560241e-04, 6.87798447e-03,\n",
       "       1.31204025e-03, 7.17018780e-04, 1.95220402e-02, 4.15462392e-04,\n",
       "       2.45790230e-03, 2.68911724e-03, 7.81863164e-03, 3.01132281e-03,\n",
       "       3.53240713e-03, 3.14934000e-03, 2.70900197e-03, 6.09573429e-04,\n",
       "       4.40945539e-04, 1.23795152e-03, 2.47410731e-03, 1.79030997e-03,\n",
       "       8.07308425e-04, 8.16626560e-03, 4.34380480e-03, 1.21526752e-03,\n",
       "       3.47187214e-03, 1.26800355e-03, 1.07421374e-03, 7.65985191e-04,\n",
       "       1.61230369e-03, 4.03394586e-03, 3.78225475e-03, 9.09501287e-03,\n",
       "       1.77333956e-03, 6.93854002e-04, 8.34472587e-04, 1.77567926e-03,\n",
       "       3.12712217e-03, 1.86183368e-03, 1.16407369e-03, 2.12935652e-03,\n",
       "       5.04214943e-04, 9.19807987e-04, 2.13063416e-03, 1.28409443e-03,\n",
       "       3.62094013e-02, 1.17209449e-03, 6.82960178e-04, 3.47163767e-03,\n",
       "       8.31670314e-03, 9.47281394e-04, 2.74348506e-03, 8.82593193e-04,\n",
       "       1.61605863e-03, 5.49229811e-04, 2.60871258e-03, 1.83775997e-07,\n",
       "       2.25263496e-03, 4.58900712e-04, 5.88658875e-04, 1.34664915e-03,\n",
       "       1.42167540e-03, 2.38859753e-03, 4.40840884e-03, 1.81464133e-03,\n",
       "       1.10907832e-02, 5.54827081e-03, 1.22902526e-03, 3.00171043e-03,\n",
       "       1.84075775e-04, 4.23326412e-03, 4.32242865e-04, 1.27001062e-03,\n",
       "       9.30001041e-04, 2.41312548e-03, 2.63519358e-04, 9.52194621e-04,\n",
       "       7.51243616e-04, 2.12919219e-03, 5.92777165e-03, 6.18950346e-03,\n",
       "       6.50354883e-04, 5.39409171e-04, 1.36805274e-03, 2.58274211e-03,\n",
       "       1.61447755e-03, 1.53742145e-03, 3.00636724e-03, 3.00397537e-03,\n",
       "       2.79006783e-04, 3.15639302e-03, 3.01581361e-03, 2.42163037e-03,\n",
       "       6.46550042e-03, 1.09417142e-03, 3.04188260e-03, 5.64516994e-03,\n",
       "       9.43303197e-04, 7.56445339e-04, 1.55386404e-03, 6.41510292e-04,\n",
       "       3.89123004e-03, 4.47926799e-04, 1.31342452e-03, 1.63018047e-03,\n",
       "       1.58459943e-03, 2.42603781e-03, 5.87933536e-04, 5.16436311e-03,\n",
       "       9.96086375e-04, 1.76644713e-02, 2.66570256e-03, 3.96047604e-03,\n",
       "       1.49351844e-03, 1.21201230e-03, 1.47781858e-03, 5.08701049e-03,\n",
       "       1.67099287e-02, 3.70754366e-03, 1.13452144e-03, 3.82521131e-03,\n",
       "       6.07077402e-03, 3.22605177e-03, 3.52580608e-03, 3.47303961e-03,\n",
       "       1.71170798e-03, 8.58460200e-03, 8.70524678e-04, 6.22271138e-03,\n",
       "       6.11889787e-03, 8.45089225e-04, 1.54368430e-03, 2.04630641e-03,\n",
       "       1.86398658e-03, 9.28388217e-03, 1.46564993e-03, 1.35615953e-02,\n",
       "       3.28291742e-03, 2.28442297e-03, 1.80878760e-04, 3.00964208e-03,\n",
       "       7.08157582e-03, 6.14935594e-04, 3.48988049e-03, 3.43499091e-03,\n",
       "       8.87762440e-04, 1.65989891e-03, 3.50252450e-03, 2.26140979e-03,\n",
       "       4.28711678e-03, 1.37084944e-03, 3.58429190e-04, 5.86922796e-04,\n",
       "       3.47790159e-03, 3.62395250e-02, 5.79621629e-03, 1.53658299e-03,\n",
       "       1.27168776e-02, 7.82556328e-04, 1.44910406e-03, 2.56976177e-02,\n",
       "       3.62826466e-03, 1.09532157e-03, 2.04399003e-02, 1.30198756e-03,\n",
       "       1.21904583e-03, 4.52684372e-03, 2.39479801e-03, 4.19532410e-03])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = clf.named_steps['regression'].feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (252, 1), indices imply (674, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m feature_importances \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(importances, index\u001b[39m=\u001b[39;49mcols, columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mimportance\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m feature_importances\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    695\u001b[0m             data,\n\u001b[1;32m    696\u001b[0m             index,\n\u001b[1;32m    697\u001b[0m             columns,\n\u001b[1;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (252, 1), indices imply (674, 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.DataFrame(importances, index=cols, columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m importances \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfeature_importances_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/willcichowski/Desktop/DS390/kaggle/data-science-regression-competition-spring-2023/dev.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(importances)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x755</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>6.605386e+09</td>\n",
       "      <td>7742.87</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>3.302693e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>59094701.70</td>\n",
       "      <td>2004759.0</td>\n",
       "      <td>1931348.0</td>\n",
       "      <td>4680000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>294000000000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>174.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>1.513234e+10</td>\n",
       "      <td>25084.63</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>2.522056e+09</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12729146.37</td>\n",
       "      <td>4407571.0</td>\n",
       "      <td>28012.0</td>\n",
       "      <td>206000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>790000000000</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.7376</td>\n",
       "      <td>159.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>4.049730e+10</td>\n",
       "      <td>11705.48</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.02360</td>\n",
       "      <td>4.049730e+09</td>\n",
       "      <td>0.40</td>\n",
       "      <td>14295800.73</td>\n",
       "      <td>2338924.0</td>\n",
       "      <td>16101.0</td>\n",
       "      <td>131000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>23800000000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.7560</td>\n",
       "      <td>116.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>4.487598e+09</td>\n",
       "      <td>14555.42</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>1.495866e+09</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2307783.94</td>\n",
       "      <td>1742760.0</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>3790000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>35600000000000</td>\n",
       "      <td>0.51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.3273</td>\n",
       "      <td>62.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2.557971e+10</td>\n",
       "      <td>11964.99</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>1.827122e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>755090.00</td>\n",
       "      <td>1408153.0</td>\n",
       "      <td>133617.0</td>\n",
       "      <td>360000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>133</td>\n",
       "      <td>0.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.8113</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>3.348799e+10</td>\n",
       "      <td>16.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>8.371996e+09</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3969.69</td>\n",
       "      <td>2897.0</td>\n",
       "      <td>2897.0</td>\n",
       "      <td>57317965</td>\n",
       "      <td>...</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3661</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>4.113460e+10</td>\n",
       "      <td>9594.43</td>\n",
       "      <td>7.48</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>1.645384e+09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>395512.92</td>\n",
       "      <td>1165014.0</td>\n",
       "      <td>158948.0</td>\n",
       "      <td>65000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>98125</td>\n",
       "      <td>0.39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0991</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>1.938843e+09</td>\n",
       "      <td>37960.50</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>9.694215e+08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8635013.87</td>\n",
       "      <td>4593266.0</td>\n",
       "      <td>9509.0</td>\n",
       "      <td>153000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>16900000000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3775</td>\n",
       "      <td>222.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>2.692091e+10</td>\n",
       "      <td>39489.18</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.922922e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>8631824.79</td>\n",
       "      <td>5279353.0</td>\n",
       "      <td>36829.0</td>\n",
       "      <td>216000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1070000000000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.2412</td>\n",
       "      <td>189.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>5.905840e+10</td>\n",
       "      <td>8185.78</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.368946e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>619551.33</td>\n",
       "      <td>972065.0</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>161000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>177880</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.1499</td>\n",
       "      <td>31.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4304 rows Ã— 685 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x001      x002  x003     x004          x005  x006         x007  \\\n",
       "5209  6.605386e+09   7742.87  4.75  0.00035  3.302693e+09  0.50  59094701.70   \n",
       "4558  1.513234e+10  25084.63  6.31  0.00035  2.522056e+09  0.37  12729146.37   \n",
       "3720  4.049730e+10  11705.48  5.41  0.02360  4.049730e+09  0.40  14295800.73   \n",
       "700   4.487598e+09  14555.42  6.71  0.00040  1.495866e+09  0.47   2307783.94   \n",
       "231   2.557971e+10  11964.99  7.02  0.00045  1.827122e+09  0.35    755090.00   \n",
       "...            ...       ...   ...      ...           ...   ...          ...   \n",
       "3335  3.348799e+10     16.75  5.75  0.00075  8.371996e+09  0.43      3969.69   \n",
       "1099  4.113460e+10   9594.43  7.48  0.00080  1.645384e+09  0.27    395512.92   \n",
       "2514  1.938843e+09  37960.50  6.14  0.00010  9.694215e+08  0.00   8635013.87   \n",
       "3606  2.692091e+10  39489.18  6.51  0.00125  1.922922e+09  0.35   8631824.79   \n",
       "2575  5.905840e+10   8185.78  6.69  0.00165  5.368946e+09  0.39    619551.33   \n",
       "\n",
       "           x008       x009                 x010  ...   x755    x756    x757  \\\n",
       "5209  2004759.0  1931348.0  4680000000000000000  ...   3.70  0.1314  1.0000   \n",
       "4558  4407571.0    28012.0   206000000000000000  ...   1.99  0.0918  0.0004   \n",
       "3720  2338924.0    16101.0   131000000000000000  ...   6.68  0.1567  0.0154   \n",
       "700   1742760.0    56041.0     3790000000000000  ...   1.15  0.0100  0.0004   \n",
       "231   1408153.0   133617.0      360000000000000  ...   3.88  0.3350  0.0002   \n",
       "...         ...        ...                  ...  ...    ...     ...     ...   \n",
       "3335     2897.0     2897.0             57317965  ...  12.88  0.1351  0.0002   \n",
       "1099  1165014.0   158948.0       65000000000000  ...   1.67  0.0400  0.0009   \n",
       "2514  4593266.0     9509.0   153000000000000000  ...   2.10  0.2743  0.0004   \n",
       "3606  5279353.0    36829.0   216000000000000000  ...   6.85  0.5777  0.0004   \n",
       "2575   972065.0     5140.0      161000000000000  ...   1.94  0.1126  0.0004   \n",
       "\n",
       "                x758  x759   x760  x761   x762     x763    x764  \n",
       "5209    294000000000  0.32  975.0     0  565.0   1.6377  174.07  \n",
       "4558    790000000000  0.51    8.0     0    3.0   4.7376  159.56  \n",
       "3720  23800000000000  0.72   19.0     1    9.0   6.7560  116.48  \n",
       "700   35600000000000  0.51   10.0     0    6.0   2.3273   62.16  \n",
       "231              133  0.01   31.0     3   18.0  10.8113   36.99  \n",
       "...              ...   ...    ...   ...    ...      ...     ...  \n",
       "3335              12  0.07    1.0     1    1.0   2.3661    0.43  \n",
       "1099           98125  0.39   25.0     4   12.0  18.0991   16.30  \n",
       "2514  16900000000000  0.89    4.0     1    3.0   1.3775  222.09  \n",
       "3606   1070000000000  0.15    5.0     1    4.0  11.2412  189.67  \n",
       "2575          177880  0.92    3.0     0    2.0   7.1499   31.82  \n",
       "\n",
       "[4304 rows x 685 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.22767997987926"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean(np.square(y_val - preds))\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
