{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check unique - some columns with only 1 value\n",
    "- check collinearity - can drop 200 columns from this\n",
    "- try models with feature_importances: decision tree and MARS\n",
    "    - stick with predictors with highest importances\n",
    "- PCA after removing collinear predictors?\n",
    "- tune models: RF, MARS, logreg (maybe), AdaBoost, XGBoost\n",
    "- Ensemble\n",
    "- Colab for RF GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3320000000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>348000000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0   0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "1   1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00  11927742.92   \n",
       "2   2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "3   3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   6324375.16   \n",
       "4   4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "\n",
       "        x008       x009  ...    x757           x758  x759   x760  x761   x762  \\\n",
       "0   934577.0    14539.0  ...  0.0007      297281012  0.13    5.0     5    2.0   \n",
       "1  1798051.0  1051272.0  ...  0.1136  3320000000000  0.08  661.0     0  350.0   \n",
       "2   375738.0   144143.0  ...  0.0029      100474819  0.39   39.0     2   18.0   \n",
       "3  1932094.0    10055.0  ...  0.0000   348000000000  0.25    2.0     1    0.0   \n",
       "4   474253.0    17914.0  ...  0.0005      109546590  0.11   11.0     1    3.0   \n",
       "\n",
       "      x763    x764  x765   y  \n",
       "0   8.5127   14.28 -0.75   5  \n",
       "1   1.5700  160.12   NaN   1  \n",
       "2   9.6800   25.06 -0.49  11  \n",
       "3   4.5316  117.76  1.64   1  \n",
       "4  16.2717    5.81 -0.42   5  \n",
       "\n",
       "[5 rows x 767 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the data\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 767)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing NAs almost halved the dataset. Two options:\n",
    "- continue as usual. performance will probably suffer.\n",
    "- imputation:\n",
    "    - mean\n",
    "    - lin reg prediction imputation?\n",
    "    - k-NN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2857, 767)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many observations have missing values\n",
    "train_dropna = train.dropna()\n",
    "train_dropna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 765)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(['id', 'y'], axis=1)\n",
    "y = train['y']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5380, 765)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>2.690000e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>1.690000e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>1.350000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>3.700000e+16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>6.000000e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 765 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x001      x002  x003     x004          x005  x006         x007  \\\n",
       "0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31    266117.20   \n",
       "1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00  11927742.92   \n",
       "2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00    774385.01   \n",
       "3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   6324375.16   \n",
       "4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21    169860.29   \n",
       "\n",
       "        x008       x009          x010  ...    x756    x757          x758  \\\n",
       "0   934577.0    14539.0  2.690000e+13  ...  1.5707  0.0007  2.972810e+08   \n",
       "1  1798051.0  1051272.0  1.690000e+17  ...  0.1173  0.1136  3.320000e+12   \n",
       "2   375738.0   144143.0  1.350000e+14  ...  0.4582  0.0029  1.004748e+08   \n",
       "3  1932094.0    10055.0  3.700000e+16  ...  0.3816  0.0000  3.480000e+11   \n",
       "4   474253.0    17914.0  6.000000e+12  ...  0.0100  0.0005  1.095466e+08   \n",
       "\n",
       "   x759   x760  x761   x762     x763    x764  x765  \n",
       "0  0.13    5.0   5.0    2.0   8.5127   14.28 -0.75  \n",
       "1  0.08  661.0   0.0  350.0   1.5700  160.12  5.96  \n",
       "2  0.39   39.0   2.0   18.0   9.6800   25.06 -0.49  \n",
       "3  0.25    2.0   1.0    0.0   4.5316  117.76  1.64  \n",
       "4  0.11   11.0   1.0    3.0  16.2717    5.81 -0.42  \n",
       "\n",
       "[5 rows x 765 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform k-nn imputation on missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "print(X_imputed.shape)\n",
    "print(X_imputed.isna().sum().sum())\n",
    "X_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x025 \n",
      " [6. 2. 1. 5. 0. 3. 4.]\n",
      "x063 \n",
      " [0.]\n",
      "x137 \n",
      " [0.]\n",
      "x255 \n",
      " [0.]\n",
      "x385 \n",
      " [0.]\n",
      "x405 \n",
      " [1.]\n",
      "x453 \n",
      " [1.]\n",
      "x465 \n",
      " [0.]\n",
      "x516 \n",
      " [0. 1.]\n",
      "x518 \n",
      " [0.]\n",
      "x556 \n",
      " [1. 0.]\n",
      "x594 \n",
      " [0.]\n",
      "x643 \n",
      " [0.]\n",
      "x703 \n",
      " [0.]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# identify variables with less than 8 unique values\n",
    "cat_nonbin = []\n",
    "for col in X_imputed.columns:\n",
    "    if (len(X_imputed[col].unique()) < 8):\n",
    "        print(col, '\\n', X_imputed[col].unique())\n",
    "        cat_nonbin.append(col)\n",
    "print(len(cat_nonbin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redundant = ['x063', 'x137', 'x255', 'x385', 'x405', 'x453', 'x465', 'x518', 'x594', 'x643', 'x703']\n",
    "redundant = []\n",
    "for col in cat_nonbin:\n",
    "    if (len(X_imputed[col].unique()) < 2):\n",
    "        redundant.append(col)\n",
    "len(redundant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 11 columns with only 1 value. Remove these since they cant be used for prediction if there is only 1 value among all instances.\n",
    "- 2 binary and 1 categorical with 7 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 756)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns with 1 unique value\n",
    "# train.drop([col for col in train.columns if len(train[col].unique()) < 2], axis=1, inplace=True)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 754)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imputed.drop(redundant, axis=1, inplace=True)\n",
    "X_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which columns are not numeric\n",
    "non_num = X_imputed.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imputed[non_num].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imputed[non_num].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert non-numeric columns to numeric\n",
    "X_imputed[non_num] = X_imputed[non_num].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN imputation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to impute missing values BEFORE checking multicollinearity!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Albert/opt/anaconda3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1736: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x001</td>\n",
       "      <td>3.772624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x002</td>\n",
       "      <td>0.475730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x003</td>\n",
       "      <td>0.023749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x004</td>\n",
       "      <td>1.192589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature       VIF\n",
       "0   const  0.000000\n",
       "1    x001  3.772624\n",
       "2    x002  0.475730\n",
       "3    x003  0.023749\n",
       "4    x004  1.192589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check multicollinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# the independent variables set\n",
    "X = add_constant(train_imputed.drop(['y', 'id'], axis=1))\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "\t\t\t\t\t\tfor i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data.shape)\n",
    "vif_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>x117</td>\n",
       "      <td>4432.831944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>x320</td>\n",
       "      <td>4323.590908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>x689</td>\n",
       "      <td>2803.881059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>x379</td>\n",
       "      <td>2712.657465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>x707</td>\n",
       "      <td>83.577763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>x189</td>\n",
       "      <td>78.844773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>x266</td>\n",
       "      <td>76.642293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>x700</td>\n",
       "      <td>53.052091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>x667</td>\n",
       "      <td>12.331969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>x181</td>\n",
       "      <td>9.982753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature          VIF\n",
       "116    x117  4432.831944\n",
       "317    x320  4323.590908\n",
       "679    x689  2803.881059\n",
       "376    x379  2712.657465\n",
       "696    x707    83.577763\n",
       "187    x189    78.844773\n",
       "263    x266    76.642293\n",
       "690    x700    53.052091\n",
       "657    x667    12.331969\n",
       "179    x181     9.982753"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_data.sort_values(by='VIF', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>x117</td>\n",
       "      <td>4432.831944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>x181</td>\n",
       "      <td>9.982753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>x189</td>\n",
       "      <td>78.844773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>x193</td>\n",
       "      <td>9.515170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>x205</td>\n",
       "      <td>7.094817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>x238</td>\n",
       "      <td>7.486376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>x266</td>\n",
       "      <td>76.642293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>x320</td>\n",
       "      <td>4323.590908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>x379</td>\n",
       "      <td>2712.657465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>x407</td>\n",
       "      <td>6.415955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>x509</td>\n",
       "      <td>9.462132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>x667</td>\n",
       "      <td>12.331969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>x689</td>\n",
       "      <td>2803.881059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>x700</td>\n",
       "      <td>53.052091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>x707</td>\n",
       "      <td>83.577763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature          VIF\n",
       "116    x117  4432.831944\n",
       "179    x181     9.982753\n",
       "187    x189    78.844773\n",
       "191    x193     9.515170\n",
       "203    x205     7.094817\n",
       "236    x238     7.486376\n",
       "263    x266    76.642293\n",
       "317    x320  4323.590908\n",
       "376    x379  2712.657465\n",
       "402    x407     6.415955\n",
       "502    x509     9.462132\n",
       "657    x667    12.331969\n",
       "679    x689  2803.881059\n",
       "690    x700    53.052091\n",
       "696    x707    83.577763"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the features with VIF > 5\n",
    "print(vif_data[vif_data['VIF'] > 5].shape)\n",
    "vif_data[vif_data['VIF'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 741)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the features with VIF > 5\n",
    "vif_features = vif_data[vif_data['VIF'] > 5]['feature'].values\n",
    "train_imputed.drop(vif_features, axis=1, inplace=True)\n",
    "train_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform PCA on the remaining features\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "train_pca = pca.fit_transform(train_imputed.drop(['y', 'id'], axis=1))\n",
    "train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82618146, 0.17381854])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.11049207014291\n",
      "Train RMSE: 12.216774597268362\n"
     ]
    }
   ],
   "source": [
    "# train linear regression model with PCA features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pca, train_imputed['y'], test_size=0.2, random_state=42)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# check train RMSE\n",
    "y_pred_train = linreg.predict(X_train)\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.507826e+10</td>\n",
       "      <td>7882.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>1.712586e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>583617.74</td>\n",
       "      <td>862986.0</td>\n",
       "      <td>63872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>90204869909</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.1213</td>\n",
       "      <td>27.95</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>3.122741e+09</td>\n",
       "      <td>4682.13</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.040914e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190000.65</td>\n",
       "      <td>688710.0</td>\n",
       "      <td>35407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>37449565014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>10.18</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.888719e+10</td>\n",
       "      <td>7495.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>2.160400e+09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>351570.67</td>\n",
       "      <td>841523.0</td>\n",
       "      <td>170240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>10847937619</td>\n",
       "      <td>0.83</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.8513</td>\n",
       "      <td>21.27</td>\n",
       "      <td>19.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>7.727427e+10</td>\n",
       "      <td>4003.76</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.519591e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320216.05</td>\n",
       "      <td>466131.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37200096</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0511</td>\n",
       "      <td>18.38</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>4.184868e+09</td>\n",
       "      <td>34874.72</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.046217e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3349978.53</td>\n",
       "      <td>3711028.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16400000000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>149.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          x001      x002  x003     x004          x005  x006  \\\n",
       "0  5380  6.507826e+10   7882.15  6.82  0.00210  1.712586e+09  0.39   \n",
       "1  5381  3.122741e+09   4682.13  8.17  0.00010  1.040914e+09  0.00   \n",
       "2  5382  3.888719e+10   7495.57  7.15  0.00285  2.160400e+09  0.42   \n",
       "3  5383  7.727427e+10   4003.76  6.53  0.00165  5.519591e+09  0.00   \n",
       "4  5384  4.184868e+09  34874.72  6.39  0.00065  1.046217e+09  0.50   \n",
       "\n",
       "         x007       x008      x009  ...    x756    x757            x758  x759  \\\n",
       "0   583617.74   862986.0   63872.0  ...  0.0380  0.0010     90204869909  0.26   \n",
       "1   190000.65   688710.0   35407.0  ...  0.1866  0.0192     37449565014  0.02   \n",
       "2   351570.67   841523.0  170240.0  ...  0.0100  0.0017     10847937619  0.83   \n",
       "3   320216.05   466131.0      35.0  ...  0.4636  0.0000        37200096  0.51   \n",
       "4  3349978.53  3711028.0    1757.0  ...  2.8737  0.0001  16400000000000  0.12   \n",
       "\n",
       "   x760  x761  x762     x763    x764   x765  \n",
       "0   8.0     5   5.0  30.1213   27.95  -0.49  \n",
       "1  16.0     1   8.0   2.1282   10.18   0.55  \n",
       "2  35.0     1  19.0   7.8513   21.27  19.09  \n",
       "3   1.0     4   0.0   9.0511   18.38   4.11  \n",
       "4   2.0     1   2.0   2.6512  149.68   0.02  \n",
       "\n",
       "[5 rows x 766 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Albert/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- x063\n",
      "- x137\n",
      "- x255\n",
      "- x385\n",
      "- x405\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- y\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 766 features, but KNNImputer is expecting 756 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/78/287t_xwn4jj_fts7vlrhv3z80000gq/T/ipykernel_14663/3531313064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 766 features, but KNNImputer is expecting 756 features as input."
     ]
    }
   ],
   "source": [
    "test_imputed = pd.DataFrame(imputer.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x117', 'x181', 'x189', 'x193', 'x205', 'x238', 'x266', 'x320',\n",
       "       'x379', 'x407', 'x509', 'x667', 'x689', 'x700', 'x707'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007', 'x008',\n",
       "       'x009',\n",
       "       ...\n",
       "       'x756', 'x757', 'x758', 'x759', 'x760', 'x761', 'x762', 'x763', 'x764',\n",
       "       'x765'],\n",
       "      dtype='object', length=740)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test data by removing redundant features, multicollinearity, and performing PCA\n",
    "test.drop(redundant, axis=1, inplace=True)\n",
    "test[non_num] = test[non_num].apply(pd.to_numeric, errors='coerce')\n",
    "test.drop(vif_features, axis=1, inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23897"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Albert/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- x117\n",
      "- x181\n",
      "- x189\n",
      "- x193\n",
      "- x205\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 740 features, but KNNImputer is expecting 756 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/78/287t_xwn4jj_fts7vlrhv3z80000gq/T/ipykernel_14663/2124217196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_imputed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 740 features, but KNNImputer is expecting 756 features as input."
     ]
    }
   ],
   "source": [
    "test_imputed = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
    "test_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pca = pca.transform(test.drop('id', axis=1))\n",
    "test_pca.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features with highest R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x689    1.000000\n",
       "x117    1.000000\n",
       "x320    1.000000\n",
       "x379    1.000000\n",
       "x039    1.000000\n",
       "          ...   \n",
       "x333   -0.579266\n",
       "x509   -0.583145\n",
       "x238   -0.583429\n",
       "x667   -0.583855\n",
       "x527   -0.585407\n",
       "Length: 765, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate R-squared for all individual features\n",
    "r2 = {}\n",
    "for feature in X:\n",
    "    model = smf.ols('y~' + feature, data=train).fit()\n",
    "    r2[feature] = model.rsquared\n",
    "\n",
    "# sort the features by R-squared\n",
    "r2 = pd.Series(r2)\n",
    "r2.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x039', 'x117', 'x320', 'x379', 'x689'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a lin reg model with the features with r-squared = 1\n",
    "r2_high = r2[r2==1]\n",
    "r2_high.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('y~x039+x117+x320+x379+x689', data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridiculous output, probably need to scale features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970642</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>1.645596</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.290630</td>\n",
       "      <td>0.292676</td>\n",
       "      <td>-0.579714</td>\n",
       "      <td>-0.612144</td>\n",
       "      <td>-0.278262</td>\n",
       "      <td>-0.254397</td>\n",
       "      <td>...</td>\n",
       "      <td>2.883526</td>\n",
       "      <td>-0.234542</td>\n",
       "      <td>-0.392860</td>\n",
       "      <td>-0.732343</td>\n",
       "      <td>-0.281474</td>\n",
       "      <td>1.289516</td>\n",
       "      <td>-0.279533</td>\n",
       "      <td>-0.229378</td>\n",
       "      <td>-0.840696</td>\n",
       "      <td>-0.493594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.823610</td>\n",
       "      <td>-0.024523</td>\n",
       "      <td>-1.275039</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>-0.712863</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.958332</td>\n",
       "      <td>-0.101080</td>\n",
       "      <td>0.742522</td>\n",
       "      <td>0.052129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588028</td>\n",
       "      <td>0.721319</td>\n",
       "      <td>-0.266476</td>\n",
       "      <td>-0.909001</td>\n",
       "      <td>1.879772</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>1.770140</td>\n",
       "      <td>-0.758149</td>\n",
       "      <td>0.732521</td>\n",
       "      <td>1.125594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269400</td>\n",
       "      <td>-0.860578</td>\n",
       "      <td>-0.786230</td>\n",
       "      <td>-0.302801</td>\n",
       "      <td>-0.270000</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>-0.512679</td>\n",
       "      <td>-0.942904</td>\n",
       "      <td>-0.150652</td>\n",
       "      <td>-0.254201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226237</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>-0.392868</td>\n",
       "      <td>0.186279</td>\n",
       "      <td>-0.169458</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.185295</td>\n",
       "      <td>-0.140474</td>\n",
       "      <td>-0.724409</td>\n",
       "      <td>-0.430854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.639890</td>\n",
       "      <td>0.145935</td>\n",
       "      <td>-0.676248</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.447124</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.219307</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>-0.282677</td>\n",
       "      <td>-0.187326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043272</td>\n",
       "      <td>-0.240469</td>\n",
       "      <td>-0.379623</td>\n",
       "      <td>-0.308364</td>\n",
       "      <td>-0.291358</td>\n",
       "      <td>-0.391612</td>\n",
       "      <td>-0.291313</td>\n",
       "      <td>-0.532588</td>\n",
       "      <td>0.275572</td>\n",
       "      <td>0.083136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.299242</td>\n",
       "      <td>-0.891836</td>\n",
       "      <td>1.352311</td>\n",
       "      <td>-0.261818</td>\n",
       "      <td>-0.852622</td>\n",
       "      <td>-0.267221</td>\n",
       "      <td>-0.592409</td>\n",
       "      <td>-0.884596</td>\n",
       "      <td>-0.274939</td>\n",
       "      <td>-0.254435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.844322</td>\n",
       "      <td>-0.236236</td>\n",
       "      <td>-0.392867</td>\n",
       "      <td>-0.803006</td>\n",
       "      <td>-0.261706</td>\n",
       "      <td>-0.391612</td>\n",
       "      <td>-0.273643</td>\n",
       "      <td>0.361564</td>\n",
       "      <td>-0.932064</td>\n",
       "      <td>-0.413962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x001      x002      x003      x004      x005      x006      x007  \\\n",
       "0  0.970642 -0.607871  1.645596  0.000475  1.290630  0.292676 -0.579714   \n",
       "1 -0.823610 -0.024523 -1.275039 -0.298702 -0.712863 -1.443005  0.958332   \n",
       "2 -0.269400 -0.860578 -0.786230 -0.302801 -0.270000 -1.443005 -0.512679   \n",
       "3 -0.639890  0.145935 -0.676248 -0.294604 -0.447124 -1.443005  0.219307   \n",
       "4 -0.299242 -0.891836  1.352311 -0.261818 -0.852622 -0.267221 -0.592409   \n",
       "\n",
       "       x008      x009      x010  ...      x756      x757      x758      x759  \\\n",
       "0 -0.612144 -0.278262 -0.254397  ...  2.883526 -0.234542 -0.392860 -0.732343   \n",
       "1 -0.101080  0.742522  0.052129  ... -0.588028  0.721319 -0.266476 -0.909001   \n",
       "2 -0.942904 -0.150652 -0.254201  ...  0.226237 -0.215916 -0.392868  0.186279   \n",
       "3 -0.021744 -0.282677 -0.187326  ...  0.043272 -0.240469 -0.379623 -0.308364   \n",
       "4 -0.884596 -0.274939 -0.254435  ... -0.844322 -0.236236 -0.392867 -0.803006   \n",
       "\n",
       "       x760      x761      x762      x763      x764      x765  \n",
       "0 -0.281474  1.289516 -0.279533 -0.229378 -0.840696 -0.493594  \n",
       "1  1.879772 -0.811894  1.770140 -0.758149  0.732521  1.125594  \n",
       "2 -0.169458  0.028670 -0.185295 -0.140474 -0.724409 -0.430854  \n",
       "3 -0.291358 -0.391612 -0.291313 -0.532588  0.275572  0.083136  \n",
       "4 -0.261706 -0.391612 -0.273643  0.361564 -0.932064 -0.413962  \n",
       "\n",
       "[5 rows x 754 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale features\n",
    "X = train_imputed.drop(['id', 'y'], axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rel = X_scaled[['x039', 'x117', 'x320', 'x379', 'x689']]\n",
    "X_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# train a model with the 5 features with r-squared = 1, using scaled features\n",
    "model = sm.OLS(y, X_rel['x039']).fit()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared is now being returned as zero - need to scale features first and then identify the most promising features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17704326, 0.12741611, 0.07525316, 0.06339   , 0.0545909 ,\n",
       "       0.03502101, 0.0256016 , 0.01978087, 0.01914396, 0.01668859,\n",
       "       0.01492525, 0.0129755 , 0.0109713 , 0.01003628, 0.00947424,\n",
       "       0.00885244, 0.00857611, 0.00805093, 0.00768955, 0.00737265,\n",
       "       0.00701066, 0.00684825, 0.00649986, 0.00622187, 0.00602958,\n",
       "       0.00575216, 0.00554243, 0.00508717, 0.00466881, 0.00450982,\n",
       "       0.00438951, 0.00428818, 0.00406028, 0.00387343, 0.00378837,\n",
       "       0.00362746, 0.00352846, 0.00341988, 0.00335787, 0.0032201 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085778356652681"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with:\n",
    "- 10 components captures 61% of the variance in the original data.\n",
    "- 20 components captures 71%\n",
    "- 30 components captures 77%\n",
    "- 40 components captures 81%\n",
    "- As expected, diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2515634102385625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linreg with pca\n",
    "y = train_imputed['y']\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "linreg = LinearRegression()\n",
    "# train linear regression with 5-fold cross validation\n",
    "scores = cross_val_score(linreg, X_pca, y, cv=5, scoring='r2')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot of y values\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 18, 'lines.markersize': 10})\n",
    "plt.hist(y, bins=100)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
